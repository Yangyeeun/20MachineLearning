{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-03. 다중 선형 회귀(Multivariable Linear regression)",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsqPZqI51s9EnFXLM9wRoh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yangyeeun/20MachineLearning/blob/master/3_03_%EB%8B%A4%EC%A4%91_%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80(Multivariable_Linear_regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LwkWQIGskf_",
        "colab_type": "text"
      },
      "source": [
        "# 03. 다중 선형 회귀(Multivariable Linear regression)\n",
        " \n",
        "단순 선형 회귀        : x가 1개로부터 y를 예측하는 선형 회귀  \n",
        "다중 선형 회귀: 다수의 x로부터 y를 예측하는 선형 회귀\n",
        "\n",
        "\n",
        "\n",
        "## 3-1) 데이터에 대한 이해(Data Definition)\n",
        "3개의 퀴즈 점수-> 최종 점수를 예측하는 모델\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/54841/%ED%9B%88%EB%A0%A8%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG)\n",
        "\n",
        "\n",
        "H(x)=w1'x1 + w2'x2 + w3'x3 + b\n",
        "\n",
        "\n",
        "## 3-2) 파이토치로 구현하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re8IvjtzvPAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "# 훈련 데이터\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# 가중치 w와 편향 b 초기화\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_TOd7O2vrXE",
        "colab_type": "text"
      },
      "source": [
        "# 3. 벡터와 행렬 연산으로 바꾸기\n",
        "\n",
        "x 의 개수가 3개 -> x와 W 각각 3개 선언  \n",
        "x의 개수가 많아지면 비효율 => **행렬 곱셈**\n",
        "\n",
        "##3-1)벡터 연산으로 이해하기\n",
        "\n",
        "![대체 텍스트](https://wikidocs.net/images/page/54841/%EB%82%B4%EC%A0%81.PNG)\n",
        "\n",
        "H(X)=XW\n",
        "\n",
        "##3-2)행렬 연산으로 이해하기\n",
        "샘플(sample): 전체 훈련 데이터의 개수를 셀 수 있는 1개의 단위 (5개)    \n",
        "특성(feature): 각 샘플에서 y를 결정하게 하는 각각의 독립 변수 x (3개)\n",
        "\n",
        "H(X)=XW+B\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXQzL8Fwu_0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  90], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        " # X_train(5 × 3) * W (3 × 1)\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}